# AUTOGENERATED! DO NOT EDIT! File to edit: 01_find_duplicates.ipynb (unless otherwise specified).

__all__ = ['get_image_path', 'load_img_as_array', 'get_hash', 'MAX_IMAGES_PER_PRODUCT', 'GetProcessRowFunc',
           'process_df_helper', 'process_df', 'contains_multiple_values_in_column', 'appears_in_multiple_categories',
           'appears_in_train_and_test', 'find_duplicates']

# Cell
from fastcore.all import *
import pandas as pd
import numpy as np
from PIL import Image
from hashlib import md5
from itertools import chain
from typing import List

# Cell
def get_image_path(data_path, _id, img_num): return data_path/"images"/f"{_id}_{img_num}.jpg"

# Cell
def load_img_as_array(path): return np.array(Image.open(path))

# Cell
def get_hash(array: np.ndarray): return md5(array.tobytes()).hexdigest()

# Cell
MAX_IMAGES_PER_PRODUCT = 4  # each product has up to 4 images

# Cell
def GetProcessRowFunc(data_path: Path, is_test: bool):
    """Get func to process row of train.csv or test_csv."""
    def _inner(*row_values):
        """Processes single row and returns (image hash, image name, _id, category_id, in_test), for each image in product."""
        if is_test: _id, = row_values
        else:       _id,category_id = row_values
        processed_row = []
        for img_num in range(MAX_IMAGES_PER_PRODUCT):
            img_path = get_image_path(data_path, _id, img_num)
            try: _hash = get_hash(load_img_as_array(img_path))
            except FileNotFoundError: break  # Processed all product's images
            processed_row.append((_hash, img_path.name, _id, -1 if is_test else category_id, is_test))
        return processed_row
    return _inner

# Cell
def process_df_helper(df, data_path: Path):
    """Processes a train/test dataframe and returns the intermediate dataframe with hashes."""
    process_row_func = GetProcessRowFunc(data_path, is_test="category_id" not in df)
    processed_products = [process_row_func(*row) for row in zip(*[df[col] for col in df.columns])]
    processed_df = pd.DataFrame(chain.from_iterable(processed_products),
                                columns=["image_hash", "image_name", "_id", "category_id", "in_test"])
    return processed_df.set_index("image_hash")

# Cell
def process_df(df, data_path: Path, n_workers=None):
    """Applies `process_df_helper` in parallel across df."""
    proc_func = partial(process_df_helper, data_path=data_path)
    chunks = np.array_split(df, int(len(df/100)))
    with ProcessPoolExecutor(max_workers=n_workers) as ex:
        res = ex.map(proc_func, chunks)
    return pd.concat(list(res))

# Cell
def contains_multiple_values_in_column(df, col): return len(df[col].unique()) > 1
def appears_in_multiple_categories(df): return contains_multiple_values_in_column(df, "category_id")
def appears_in_train_and_test(df): return contains_multiple_values_in_column(df, "in_test")

# Cell
@call_parse
def find_duplicates(
    path: Param("Path to data dir", type=Path),
    n_workers: Param("Number of workers, defaults to all cores", type=int)=None,
) -> List[pd.DataFrame]:
    """Checks for duplicates."""
    # Process CSVs
    csv_paths = L(path/"train.csv", path/"test.csv")
    dfs = []
    for csv_path in csv_paths:
        save_path = csv_path.with_name(f"{csv_path.stem}_hashes.csv")
        if save_path.exists(): break  # File previously processed
        processed_df = process_df(pd.read_csv(csv_path), data_path=path, n_workers=n_workers)
        processed_df.to_csv(save_path)
        dfs.append(processed_df)
    intermediate_df = pd.concat(dfs) if len(dfs) > 1 else dfs[0]

    # Check for duplicates
    duplicated_imgs_df = intermediate_df.groupby("image_hash")
    multiple_categories_df = duplicated_imgs_df.filter(appears_in_multiple_categories)
    in_train_and_test_df = duplicated_imgs_df.filter(appears_in_train_and_test)
    both_df = multiple_categories_df.merge(in_train_and_test_df)

    # Save results
    multiple_categories_df.to_csv(path/"multiple_categories.csv")
    in_train_and_test_df.to_csv(path/"in_train_and_test.csv")
    both_df.to_csv(path/"multiple_categories_and_in_train_and_test.csv", index=False)
    return multiple_categories_df, in_train_and_test_df, both_df
