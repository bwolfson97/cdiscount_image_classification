# AUTOGENERATED! DO NOT EDIT! File to edit: 01_find_duplicates.ipynb (unless otherwise specified).

__all__ = ['get_image_path', 'get_hash', 'MAX_IMAGES_PER_PRODUCT', 'process_df', 'contains_multiple_values_in_column',
           'appears_in_multiple_categories', 'appears_in_train_and_test', 'set_index_and_sort', 'find_duplicates']

# Cell
from fastcore.all import *
import pandas as pd
import numpy as np
from PIL import Image
from hashlib import md5
from itertools import chain
from typing import List
from multiprocessing import Pool

# Cell
def get_image_path(data_path, _id, img_num): return data_path/"images"/f"{_id}_{img_num}.jpg"

# Cell
def get_hash(img_path: Path): return md5(img_path.read_bytes()).hexdigest()

# Cell
MAX_IMAGES_PER_PRODUCT = 4  # each product has up to 4 images

# Cell
def process_df(df, data_path: Path):
    proc_func = partial(process_row, data_path=data_path, is_test="category_id" not in df.columns)
    rows = zip(*[df[col] for col in df.columns])
    proc_products = parallel(proc_func, rows, total=len(df), progress=True, chunksize=100000)
    columns = ["image_hash", "image_name", "_id", "category_id", "in_test"]
    return pd.DataFrame([row for product in proc_products for row in product], columns=columns)

# Cell
def contains_multiple_values_in_column(df, col): return len(df[col].unique()) > 1
def appears_in_multiple_categories(df): return contains_multiple_values_in_column(df, "category_id")
def appears_in_train_and_test(df): return contains_multiple_values_in_column(df, "in_test")

# Cell
def set_index_and_sort(df):
    """Sets indices, and sorts."""
    multi_index = ["image_hash", "image_name"]
    df.set_index(multi_index, inplace=True)
    df.sort_index(level=multi_index, inplace=True)
    return df

# Cell
@call_parse
def find_duplicates(
    path:       Param("Path to data dir", type=Path),
) -> List[pd.DataFrame]:
    """Checks for duplicates."""
    print(f"Finding duplicates in path: {path}")
    # Process CSVs
    csv_paths = L(path/"train.csv", path/"test.csv")
    dfs = []
    for csv_path in csv_paths:
        save_path = csv_path.with_name(f"{csv_path.stem}_hashes.csv")
        if save_path.exists():  # File previously processed
            processed_df = pd.read_csv(save_path)
        else:
            print(f"Processing {csv_path.name}")
            processed_df = process_df(pd.read_csv(csv_path), data_path=path)
            print(f"Finished processing {csv_path.name}. Saving to: {save_path}")
            processed_df.to_csv(save_path, index=False)
        dfs.append(processed_df)
    intermediate_train_df,intermediate_test_df = dfs

    # Check for duplicates
    duplicated_images_train_df = intermediate_train_df.groupby("image_hash")
    multiple_categories_df = duplicated_images_train_df.filter(appears_in_multiple_categories)

    duplicated_imgs_df = pd.concat([intermediate_train_df, intermediate_test_df]).groupby("image_hash")
    in_train_and_test_df = duplicated_imgs_df.filter(appears_in_train_and_test)
    both_df = multiple_categories_df.merge(in_train_and_test_df)
    multiple_categories_df,in_train_and_test_df,both_df = L(multiple_categories_df,in_train_and_test_df,both_df
                                                           ).map(set_index_and_sort)

    # Save results
    multiple_categories_df.to_csv(path/"multiple_categories.csv")
    in_train_and_test_df.to_csv(path/"in_train_and_test.csv")
    both_df.to_csv(path/"multiple_categories_and_in_train_and_test.csv")
    return multiple_categories_df, in_train_and_test_df, both_df