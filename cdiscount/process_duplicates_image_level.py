# AUTOGENERATED! DO NOT EDIT! File to edit: 02_process_duplicates_image_level.ipynb (unless otherwise specified).

__all__ = ['create_vocab', 'convert_category_lists_to_probability_vectors', 'get_image_level_csvs']

# Cell
from fastcore.all import *
from .find_duplicates import set_index_and_sort
import pandas as pd
from PIL import Image

# Cell
def create_vocab(category_names_df):
    categories = L(category_names_df.category_id.unique().tolist())
    categories.sort()
    return categories.val2idx()

# Cell
def _category_list_to_probability_vector_helper(category_list, vocab):
    """Converts list of categories to probability vector."""
    probs = np.zeros(len(vocab))
    for category in category_list:
        probs[vocab[category]] += 1/len(category_list)
    return probs

# Cell
def convert_category_lists_to_probability_vectors(hash2categories: dict, vocab: dict):
    """Converts hash2categories category lists to probability vectors."""
    for hash_, category_list in hash2categories.items():
        hash2categories[hash_] = _category_list_to_probability_vector_helper(category_list, vocab)

# Cell
@call_parse
def get_image_level_csvs(path: Param("Path to dir containing train_hashes.csv and test_hashes.csv", Path)="."):
    """Process duplicated images for image-level predictions.

    Saves the following CSVs in folder called "image_level_csv":
    - test_labeled.csv:      Test images duplicated in train, mapped to list of labels in train.
    - test_to_predict.csv:   Test images not duplicated in train, to predict on.
    - train_non_duplicated.csv: Train images not duplicated in test, to train on.
    """
    train_hashes_df,test_hashes_df = L("train_hashes.csv", "test_hashes.csv").map(
                                lambda f: pd.read_csv(path/f, index_col=["image_hash", "image_name"]).sort_index())
    test_imgs_in_train_idxs = get_duplicated_image_idxs(test_hashes_df, train_hashes_df)
    train_imgs_in_test_idxs = get_duplicated_image_idxs(train_hashes_df, test_hashes_df)
    assert (set(_get_unique_hashes(test_hashes_df[test_imgs_in_train_idxs])) ==
            set(_get_unique_hashes(train_hashes_df[train_imgs_in_test_idxs])))

    # Create save dir
    save_path = path/"image_level_csvs"
    save_path.mkdir(exist_ok=True)

    print("Creating test_labeled.csv")
    test_labeled_df = get_test_imgs_to_train_categories(test_hashes_df[test_imgs_in_train_idxs], train_hashes_df)
    test_labeled_df.to_csv(save_path/"test_labeled.csv", index=False)
    print("Done")

    print("Creating test_to_predict.csv")
    test_to_predict_df = test_hashes_df.reset_index()[~test_imgs_in_train_idxs]["image_name"]
    test_to_predict_df.to_csv(save_path/"test_to_predict.csv", index=False)
    print("Done")

    # Check that test_labeled and test_to_predict are disjoint on image_name
    assert len(set(test_labeled_df.image_name) & set(test_to_predict_df)) == 0, "Overlap b/t test_labeled and test_to_predict"


    print("Creating train_non_duplicated.csv")
    train_non_duplicated_df = train_hashes_df.reset_index()[~train_imgs_in_test_idxs][["image_name", "category_id"]]
    train_non_duplicated_df.to_csv(save_path/"train_non_duplicated.csv", index=False)
    print("Done")

    print("Script completed.")
    return test_labeled_df, test_to_predict_df, train_non_duplicated_df